 - Okay, so welcome. Today, we start talking about electronic identity as a
   more general concept. In the past courses, we have discussed several times
   about authentication, but when an information system becomes really large
   and really complex, you need ways to manage in a unified way authentication,
   because having separate authentication systems or separate subsystem is
   creating opportunities for the attackers. So now we are discussing in
   general electronic identity with delegated and federated authentication. And
   as you will see, once we have a strongly authenticated an actor, we can
   perform access control based on some policies. So let's start with the
   concept of delegated authentication. In general, in the system, we have
   several relying parties. Relying parties are servers that rely on an
   authentication system to properly perform authentication. So these relying
   parties may decide not to perform by themselves the authentication
   procedures, but to delegate authentication to a separate entity, which is
   normally named the authentication server. Unfortunately, you will see that
   we have several different terms for the same kind of things. For example,
   last year, when we had the basic exam of cybersecurity, we were talking
   about a verifier for performing that task. In this environment with
   delegated authentication, the verifier is named the authentication server.
   So the authentication server is performing authentication on behalf of the
   relying party. But since it is acting on behalf, at some point, we'll have
   also to send back the result. So first, it will run an authentication
   protocol with the client trying to access the service, and then will provide
   to the relying party the authentication result in a form that can take
   different names. Sometimes we call it a ticket. Sometimes we call it an
   assertion. So this is the general schema. We've got a client that wishes to
   access a service provided by a relying party. And then we've got an
   authentication server, which is the central point for authentication. So the
   client will send to relying party an application-level request. I would like
   to look at this page. Wait a moment, I need to know your identity to check
   if you are authorized or not. So the relying party will respond not
   providing the service, but performing a redirect towards the authentication
   server. If you want to access me, first, go there and authenticate yourself.
   Now, the authentication server will run one authentication protocol. Can be
   anything, can be challenge response, can be one-time password, can be
   Kerberos tickets. I don't care. That is specific between the authentication
   server and the client. The important point is that in the end, the result of
   the authentication is communicated to the relying party in some form. So the
   transmission of the authentication result may happen in several ways.
   Authentication server can transmit the authentication result in different
   ways, which differ for speed, so reaction time, when the authentication is
   finished. Security and the trust that you must think to have in the result,
   but also implication on the services provided, the interfaces that need to
   be available, and eventually also interaction with network filters, such as
   network firewalls. There is no correct or best solution. So you have to
   evaluate, given a specific environment, which is the best solution. And
   sometimes you have conflicting requirements. An authentication server is
   only providing one way to transmit the result, but that is not compatible
   with your environment. So it's really a complex matters. So you should
   select based on your application scenario. Let me concentrate on this last
   phase, communication between the authentication server and the relying
   party. First example, a push ticket. So authentication has been performed,
   and in step four, the authentication result is pushed from the
   authentication server to the relying party in the form of some statement
   that may be named ticket, may be named assertion, no problem, okay? So the
   ticket is sent directly from the authentication server to the relying party.
   Of course, you must think that this kind of communication must be possible.
   For example, network filters will permit that, and that you can relate the
   result to that specific request. So there are a lot of things to be
   discussed, and we will do that later. First, we analyze the various
   alternatives. Second, indirect push. Since a direct communication between
   the authentication server and the relying party may be impossible for
   various reasons, an alternative is that the ticket is generated by the
   authentication server, given to the client, and then the client will send it
   to the relying party. Do you have already an example of this in the past?
   Kerberos, yeah? Kerberos is a good example of this solution. Ticket is sent
   from authentication server to client, and then from client to the relying
   party. Finally, there is a third option with a push of the reference and the
   pull of the ticket. So the ticket reference is sent from the authentication
   server to the client, and then from the client to the relying party. And
   then the ticket will be pulled from the relying party. So here, I don't send
   the ticket. I send a reference. Yes, the result of your authentication is
   available as ticket number 39, but I'm transferring 39, not the real ticket.
   Once that reference is sent to the relying party, the relying party will
   talk to the authentication server, please give me the result number 39, and
   that one will be submitted as a result. Each of these have pros, cons,
   implications on the interfaces. So, first problem that we must always
   analyze, how do we bind the ticket with this specific client and this
   specific request? If we are not able to do that, then the solution may be
   attacked by, in which way? If I'm not able to bind the response to a
   specific client. Replay. If I take an answer which is not for this specific
   client and they can use for any client, I just make a copy and reuse
   whenever I want. Ticket authentication. Is the ticket really coming from the
   authentication server or it's a fake ticket, maybe generated by another
   authentication server or created by myself? Ticket manipulation. There are
   cases in which the ticket is passed through the client, so the client may
   alter that ticket, if not adequately protected. Ticket manipulation by a man
   in the middle, not by the client. So that is related to the security of the
   transmission of the ticket in the various steps. Ticket sniffing, which is
   different from manipulation. Sniffing is just reading. And that, even if,
   for example, we suppose that the ticket is protected for authentication and
   integrity, is exposing another problem, privacy. Because maybe the ticket is
   saying that Lyoi is authorized to access a website that is expressing
   political, religious opinions. So just sniffing that the ticket is
   authorizing me to do that, it's a violation of my privacy. Then we have the
   problem of the relying party. Is the relying party exposing over the network
   a service which is listening to the answers provided by the authentication
   server? If you do not accept incoming connections to the relying party, then
   we have another problem in the communication. We cannot use direct
   communication. In the same way, not only if we don't accept listening
   service, but if we have an incoming firewall, can we identify who is the
   authentication server permitted to connect to my relying party to send the
   answer? And then ticket replay, not only when the ticket is not bound with
   the client, but by the same client. Because the client is a machine. So
   maybe that I have got one ticket when the user Lyoi was using this machine,
   but then the user Atsen is coming on the same machine and they will reuse
   the ticket. Can I bind the ticket to the identity of the person using that
   machine? Ticket reuse, is the ticket really tied to this client or can I
   move it to a different client? That is ticket reuse. Okay, so given all
   those kinds of attacks, we need some kind of protection of the ticket. We
   cannot just send some data and hope that everything goes well. In the case
   of the direct transmission between the authentication server and the relying
   party, so the first case, the push of the ticket, we have different
   solutions. One solution could be, let's create a digital signature by the
   authentication server that will provide authentication and integrity, plus
   encryption of the data with a key possessed by the relying party. So now we
   have full protection, not possible to copy, not possible to modify and so
   on. Or if you prefer, you can create a secure channel where the requirement
   of the secure channel is to have the authentication of the authentication
   server to be sure that the data are coming from that server. Then the
   channel should provide data integrity authentication, should provide also
   data encryption and no replay. So for example, a TLS channel with client
   authentication is required if there is a push. Of course, if there is a
   pull, it's vice versa. We would like to have server authentication. Indirect
   transmission via client. In that case, we surely need, and there is no other
   option, digital signature by the authentication server, plus encryption for
   the relying party. That is ensuring that the data cannot be read and cannot
   be modified, neither in transit, nor by a man in the middle, nor by the
   client itself. And in general, protection for replay or reuse requires two
   things. First of all, a timestamp. With some time limit. I have generated
   this ticket at this time, and it is valid for a certain amount of time. That
   should be short. Well, if you make it too short, it will not work if it is
   passing through the client because it takes time for the transmission. But
   if it is too long, maybe the ticket is still valid with another user and
   using it. And then there is a problem of binding the ticket with the ID of
   the user that authenticated. And eventually, if you want, also the network
   address. That is your choice. If you want to bind only to the user, also to
   the address. So in that case, if the same user is going to another address,
   you will need to regenerate the ticket. And that can be a problem. Think,
   for example, if you got a ticket and then you move your laptop to another
   area in which the Wi-Fi are assigning you another address. In that case, if
   you have bound the ticket to the address, that will not work. And you will
   need to perform authentication again. But it's a more strong form of
   protection if someone is stealing your ticket and moving it to a different
   address. So delegated authentication is normally performed inside one
   organization. Let's say one security domain. There is a set of relying
   parties that trust the authentication server to perform the correct
   operations. When we talk on the contrary about federated authentication, it
   means that we have different security domains that want to trust each other
   for performing authentication. And that is becoming even more complex. So
   various security domains, each one managed by a different authentication
   server. So we need to create a trust relationship so that the relying party
   belonging to one domain will accept the authentication performed by the
   authentication server in another domain. I think, for example, Politecnico
   di Torino and Politecnico di Milano, we could create a federation so that I
   can authenticate with Torino and yet access a service in Milan.
   Unfortunately, in this case, the actors are renamed in another way. What was
   the authentication server in the delegated authentication schema is becoming
   an identity provider, IDP. And what was named the relying party is now
   renamed service provider. The concepts are very similar. Unfortunately, the
   terms are changed. Okay, so those are the general concepts. Now, we try to
   implement that in several ways that we are going to discuss. And first of
   all, we are talking about this language, XACML, Extensible Access Control
   Markup Language, because once you have authenticated, then you will perform
   some action that will be subject to authorization or access control. So
   XACML is a language to describe authorization policies, defined in terms of
   a subject that can be any actor. Go back to the definitions over the last
   year in which we said authentication is for actors, maybe human users, maybe
   devices, computer, maybe programs, so services. I don't care. That is the
   subject interacting in the system towards a resource. So a certain subject
   wants to access a certain resource, maybe a document, maybe a file, maybe
   some data. The only restriction is that XACML was developed for the web, so
   the resource is to be identified through a URI. But I hope that you know
   that the URIs can also be local files, because there is the special method
   file column or tell you a local file. It's, in general, a language to manage
   access to resources protected by authorization. So XACML is defining the
   data format to represent the request and the response transmitted over any
   client-server protocol. So XACML is a language and not a protocol. You can
   decide to transmit that in whatever way you like, inside the UDP packet, as
   part of an HTTP transaction. I don't care. XACML is just a language. It is
   an OASIS standard based on XML syntax. This is the last development or
   concept that emerged a lot of time ago. It was a model designed by the ITF
   for the description of admission control policy for quality of service on
   routers. There was some subject requesting a service, and the service is, I
   want quality of service for my packets. These are the two RFCs that defined
   the original this work. For that purpose, it was never used. But the idea
   said, OK, maybe for networks, we are not able to implement. But for local
   systems and delegated federated authentication, it is possible. So there is
   the DMTF, Distributed Management Task Force, which is fostering the adoption
   of XACML for management of information systems. And then there is OASIS, the
   group behind all web and XML stuff, which wants to use that for access
   control in distributed environments. So there is an architecture using
   XACML. And the architecture is the general architecture that you can have,
   even if you don't have XACML. Pay attention to that. This architecture was
   born with XACML. Actually, nowadays, no one is using XACML. It's a language
   that is defined, but there is a scarce application. But the architecture
   behind that, on the contrary, is very successful. And we use it with
   different languages that we will discuss in a moment. So this part is the
   really important one. And we have four elements. PEP, Policy Enforcement
   Point, the one which is providing access control. It protects a resource,
   verifying if the type of access requested is compatible with the security
   policy. PDP, Policy Decision Point. It's the one contacted by the PEP to
   tell the PEP which is the policy that applies to this specific request. PIP,
   Policy Information Point, is an auxiliary service providing extra
   information with respect to the request. And finally, PAP, Policy Access
   Point, is the service which is managing the repository of the security
   policies of the company. OK, so these elements are organized in the
   following way. This is the general architecture of a policy-based access
   control, independent of SACML, and be implemented in several ways. But the
   terms are always those. So we got a policy repository somewhere in the
   company where we have some rules. For example, professors can look at the
   data of the students, or only the professor in charge of this course can put
   the grades for that course, and so on. There is a list of policies. Great.
   Those policies have been created by a policy administrator or security
   manager using the PAP, the one that permits to manage the policies. If you
   don't have the policies, the rest of the system is useless. Now, once the
   policies have been defined, we can create an access control system based on
   those. We have a subject, as I said, human being, computer, service, that
   wants to perform an access of type T towards an object. But the object is a
   protected object. In front of that, there is the PAP, the Policy Enforcement
   Point. So the PAP is in charge of stopping any request until verification,
   if the security policy is satisfied or not. So the subject is sending a
   triplet. I'm the subject, this. My target is the object O, and I want to
   perform an access of type T. For example, I would like to write in the
   object table of students for the course Advanced Information Systems
   Security. That is the request. You see here that we have a connection with
   the authentication, because the subject must be proven its identity through
   some way that is performed through an IDP or authentication server. Now, the
   PAP has got the problem to verify. So the PAP will emit a request with the
   policy decision point. Oh, great. Please tell me if this kind of access
   should be permitted or denied. The PDP may-- it's not compulsory-- consult a
   PIP to provide some context information. One very simple example could be,
   for example, the date and time. I would not trust the date and time
   transmitted by the subject, but would ask a trusted reference, please tell
   me what is the current date and time to check if this access is permitted at
   this time of the day or this day of the week. Or I can ask geolocation. This
   request is coming from this IP address. Can please tell me in which part of
   the world is this address located? So there are additional information that
   may be helpful in taking a decision. Of course, it depends on what you have
   written in the security policy. If the policy is independent of location,
   time, or date of the week, of course, those information are not needed. But
   in a general schema, that may be important. Now, typically, if you use
   SACLM, SACLM starts here. The context handler is handling the eventual
   context information, but in a way is handling the request, carrying that
   inside an SACLM request. Now the policy decision point will consult the
   policies. OK, there is this subject and this object. Let me check what the
   policies are saying about this payer. And we'll take a decision transmitted
   as a SACLM response. The context handler has the task of translating that to
   the language which is understood by the PEP. So the response will be
   provided, and maybe it's authorized or denied. Even when originally the
   system was devised, we never thought that all the PEPs would go to SACLM,
   because there are too many systems for access control. And so SACLM was
   anyway confined to this internal dialogue. And now you can understand why
   SACLM is going to be a dead language. It's too small its scope. We don't
   need that. So the context handler, which is this additional element, because
   the PEP is typically tightly bound to the application of service. Maybe it's
   a web server, maybe it's an XML firewall, and uses specific formats for
   request and responses. There are a few policy enforcement points capable to
   using directly SACLM. The context handler has the task to convert access to
   request and response in SACLM, but also to enhance the request with the
   attribute values. Often, this addition is the form of SAML assertions. SAML
   is our next topic, because this is one language which is really used in
   implementation of current system, because it's more general. SACLM is just
   for policies. SAML is for general assertions, which is a much wider scope.
   So we just skip very quickly about these two things. SACLM defines a policy
   format where there is a set containing several policies. Each policy
   contains a rule, the effect, and the condition, which applies to a target.
   So policies are organized by the target, the object that you want to go. And
   then for that target, there is a list of subject, action, and resources. The
   request format contains one request with the resource, action, and subject,
   and attributes to identify the subject, request, or resource. You see that
   the attribute ID can be, this is a username, this is a distinguished name
   for X.509, an action, a URI, and then you have the corresponding value. So
   this is a general format to identify anything that we need to identify
   inside SACLM. And the response format encapsulates the decision with the
   result, the decision, and eventually the status to be more concise. Great.
   So from SACLM, just remember that that was the root, not applied actually
   anymore. But the general schema for policy-based access control is still
   there nowadays, simply not implemented with SACLM, because that was a very
   small area. Now we see how that is really implemented. And in practice, that
   is implemented via SAML, which is Security Assertion Markup Language. And by
   the way, tomorrow I will teach the first part of the lecture, 1.5 hours. The
   last 1.5 hours will be Andrea Zeni, that will show you SAML in operations,
   in order to have the things that we explain in theory here, demonstrated in
   practice for accessing various authentication systems. So Security Assertion
   Markup Language. Again, it's a language, so a data format, used to represent
   the various type of assertions, but also to construct a request and to
   represent a response. Again, it's not a protocol. It's just data format for
   three things-- the assertion itself, the request for an assertion, and the
   response to an assertion. Assertion is a decision, that is the base object
   of this language. The purpose of SAML was to simplify and standardize the
   interaction that are needed to permit operations in a multi-domain
   distributed system. Because if you are in a single domain, no problem.
   Because there will be some system that can directly give operations. But
   when you are multi-domain, you need to build a trust. And SAML is one of
   those things that are used to build a trust across different security
   domains. It's an OASIS standard, so you will find all the specification on
   the OASIS website. And there is, if you want, a very useful online tool to
   encode and decode various SAML formats and messages. There is the page.
   Various versions, SAML 1.0, November 2002, original version, 1.1, September
   2003, was already an improvement because request responses and data can be
   digitally signed with the XML DSIG format. That is a target of one of our
   next lectures. And additionally, since SAML is very wide in scope, they
   started defining profiles. OK, if you want to use SAML for permitting and
   controlling web access, the so-called web browser single sign-on, then you
   can use two different profiles. One profile is named browser artifact, in
   which the token generated by SAML is accessed by reference. Or the browser
   post profile, in which the token is given directly in the transaction, so it
   is by value. If you want, you can think by value as the push. On the
   contrary, the token SAML by reference is the last case in which we push the
   reference, and then we will pull the data. Actually, we are using now SAML
   2.0, March 2005. This is incompatible with previous version, so there is no
   interoperability. But luckily, everybody now is moving to SAML 2.0. Still
   can protect XML messages with signatures and can optionally use XML
   encryption for some parts of the messages, identifier, attributes, and
   assertions themselves. So the purpose is to protect the privacy of the user,
   not displaying the kind of request or the kind of permissions that they were
   given. It's incompatible because it defines new protocols, new bindings, and
   new profiles. So let's start to see the typical cases that have generated
   the various usage of SAML. The first one is named web browser, single
   sign-on use case. The point is this. We have a web user that want to access
   and protect the resources hosted at a destination website, which, in our
   words, is the service provider or relying party. In order to do that, it
   will authenticate to the identity provider, which is a source website. You
   see, it's still a website because SAML was developed basically for the web.
   And because this is the web single sign-on case, if you think you have seen
   example of this, you know that, for example, you can use Google
   authentication to access other pages. There are other services that let you
   log in using an authentication provided by Google, by Facebook, and so on.
   So this is an example, and we will discuss that. So those are the three
   elements. The second case is the authorization service use case. And if you
   check this, oh, this is what we just explained with SACLM. We got a user
   requesting access. There is an access control point, the PEP, that will use
   SAML to check permission with the PDP. So the schema of SACLM now has been
   re-implemented using SAML. And finally, the third use case is the so-called
   back-office transaction. I am a professor of Politecnico Torino, and I would
   like to buy something from a seller, but not for myself, but on behalf of
   the Politecnico. In order to be enabled to do that, so I can go to a shop
   and say, OK, I buy this, but I don't pay, charge it to Politecnico. Is that
   feasible? Yeah, if first I have authenticated myself to an authority which
   is known to both, and I have qualified as I am a professor, and I have the
   right to perform this transaction, but the payment will be done by the
   Politecnico. In that case, I will receive an assertion that, yes, you are
   entitled to do that. And that assertion will be provided to the seller. So
   in order to satisfy those three use cases, several kinds of assertions are
   needed. Basically, let's start with the general concept. An assertion is a
   declaration of the fact that regards a subject, maybe the role of the user,
   for example. And this declaration is made by a certain issuer. There are
   three basic types of assertions all regarding security-- authentication,
   authorization decision, and attributes. Those are the basic. SAML is an
   extensible language, so you can define your own assertions. But of course,
   that will create a closed system, because they are not defined in the
   standard. So before extending SAML with your own assertions, think twice and
   check if you can do the same with the standard assertions. Assertions can be
   optionally signed by using XML signature. Why optional? Because we have seen
   that we have the option to create, on the contrary, a TLS channel if we have
   a direct trust with the other node. Whatever is the kind of assertion, all
   of them contain some common elements-- the issuer name and the time stamp of
   when it was created, an assertion identifier for simple reference, then the
   subject to which this assertion is referred to, which is a name plus a
   security domain. Because remember that we are multi-domain here, so saying
   that there is a user Lyoi is not meaningful. There are various Lyois around
   the world. Unless you say Lyoi in the domain of the Politecnico di Torino,
   that would not be enough qualified. There may be conditions for which the
   assertion is valid. And some clients must reject assertion containing
   conditions that are not understood. So this is similar to the critical
   extensions in X.509. If you don't understand that condition, you should
   reject the whole assertion. An important condition is assertion validity
   period. So the lifetime of this assertion, for how much time it can be used
   for demonstrating something. Other explanations that may be useful for some
   assertion is an explanation or a proof of the basis on which the assertion
   was constructed. Yeah, the user was authenticated. Great. Can you tell me
   more? Was authenticated with username and password? Was authenticated with
   challenge response? With the one-time password? Was authenticated with the
   German federal system? That is helpful. That is, if you want context
   information, which is giving you more data to take your decision. Because
   maybe that username and password is not enough. For example, when I connect
   to the web server of the Politecnico, if I connect with username and
   password, I can only read the data. If I needed to insert the grades for the
   student, I need to authenticate with the challenge response and digital
   signature. Otherwise, I cannot do. So in any case, I get an assertion. Yes,
   Leo was authenticated. But in one case, it is authenticated with password.
   In another case, authenticated with asymmetric key. And that will give me
   different permissions on the access control system. So let's start with the
   first one. Authentication assertion. This is typically the result of what we
   discussed before, the ticket that we were saying. So there is an issue, the
   IDP, or the authentication server, as you prefer, that the subject S was
   authenticated with the mechanism M-- password, one-time password, other
   things-- at time T. Beware, SAML is not performing authentication. That is
   another part, is the authentication protocol. SAML is just carrying the
   result of the authentication to whoever interested. So it provides a
   mechanism to create a link with the result of an authentication performing
   previously by a dedicated authentication agent. Let's have a look at an
   example. This is XML, so this is SAML assertion object. Major version 1,
   minor version 0. Assertion identifier. Assertion are often, but not
   compulsory. This can be any string. But quite often, the ID is the IP
   address of the node that generated that plus a serial number. And then there
   is the issuer, Polytechnical Torino. The issuer instant, this was created at
   this date and time. And the conditions. This assertion is not valid before
   this time, and it's not valid after this time. So a five minutes period in
   which I can use that to prove my identity to an identity provider or service
   provider. Then there is the authentication statement itself. Authentication
   method, password. So I use the reusable password. Authentication instant,
   the moment in which the authentication concluded successfully. And then the
   subject. Name identifier, you see, security domain, polito.it, name, alioi.
   End of the subject, end of the statement, end of the assertion. So it is
   carrying all relevant information. This is the result of an authentication
   operation. If you have questions, you can put them. OK. Other kind,
   attribute assertion. An issuer declares that the subject S is associated
   with various attributes, attribute A, B, C, that have some values, A, B, C,
   D, and so on. Quite often, this is obtained, for example, as a result by a
   query to a database like LDAP database. An example could be that the subject
   alioi in the domain polito.it is associated with the attribute department,
   which has value, the win. And this is the real statement. I have skipped the
   initial parts that are similar to the ones that we have already seen. And we
   concentrate on the attribute statement. Subject, again, has the same form,
   domain and name. Then the attributes. Here there is an attribute name,
   dipartimento. Attribute name space, because each name, each domain has got a
   list of value departments. The attribute value is the win, and that is the
   end of the statement. This is department, but could be a role, for example.
   This is a professor, this is a student, this is an administrative employee,
   this is the rector, and so on. That is other example of attributes. And
   finally, the third standard type of assertion is authorization decision. An
   issuer declares that it has taken a decision regarding an access request. So
   there was a request to access a certain resource, R. The request was coming,
   was related to subject S. And the access type is T. And the decision was
   taken based on the evidence E. So the assertion is also explaining why the
   access was permitted or rejected. These kinds of things that seems useless
   are very useful in case there are any problems. If in the future it happens
   that you say, oh, but this person created some problem in the system. Why
   have you left it to connect to the system? Oh, I permitted this access
   because the security policy at line 35 told me, yeah, you should let it. And
   that is the evidence on which the decision was taken. Just to say, oh, I
   just implemented the rules. I've not taken a decision. On the contrary, if
   there is no evidence, maybe you were wrong in taking your decision. So the
   subject can be a person or a program. And the resource can be anything, a
   web page, a file, a web service. And here is an example. Again, we skip the
   common parts. The core is an authorization statement with the decision
   permit. So access has been allowed. The resource, for example, in this case
   is a web page. The subject, as usual, the Politecnico di Torino and the name
   Alioi. In this case, there is no evidence listed. That is not compulsory.
   It's optional. And in this case, it was not generated. So I think we can
   stop here for a first break. And then we will see how to use-- OK, there is
   a question. There are two namespaces. So one is the security domain for the
   name of the subject. The other is the namespace for that attribute. If you
   are discussing the attribute department, the department at Politecnico di
   Torino have certain names. At Politecnico di Milano, I have other names. At
   the University of New York, I have other names. So you define a namespace.
   OK, beware that the value that I'm expressing is referring to that list.
   Because otherwise, we would need to have an agreement worldwide to all
   possible names, which is not, of course, feasible. Let's have a 10-minute
   break, and then we will continue. And first of all, let me put a couple of
   comments related to questions that I received during the break. One question
   was about, where is the signature here? Because I told you that this can be
   signed. Well, the signature is not here, because it is an XML signature.
   That will be something that we will discuss in the next lectures. And it is
   a way to sign whatever XML object. It's generic. So this is an XML object.
   Great. And we can apply an XML signature. So you don't need to attach
   specifically the format of the signature. If it is an XML object, it can be
   signed with an XML signature. So that is the first message. So you will see
   that. Second question was about, who is signing this? Is the authentication
   server? The answer, no, these things are signed by the issuer. And in that
   sense, it depends upon what we are saying. For example, in this case, who is
   generating the assertion? The source website, because he performed the
   authentication. So he will generate an authentication assertion and will
   sign it. So the issuer of the authentication assertion will sign. In this
   schema, who is creating the assertion? The PDP, because it took the
   decision. So it will create not an authentication assertion. It will create
   an authorization assertion and will sign. I am the PDP. I've taken this
   decision. And this is the statement, signed by me. And in this one, who is
   creating the assertion? Who? The authority. And which kind of assertion is
   generated? An attribute assertion, because that one is saying, OK, I attest
   that Antonio Lioi has the attribute delegate of Politecnico for buying a
   computer. And the signature will be by the authority. You see? So in
   general, the signature is by the issuer that created that specific
   assertion. And the assertion depends on the contest. Now, let's have a look.
   Because we have these three basic assertion-- authentication, attribute, and
   authorization decision. There is, in general, a producer-consumer model.
   Because, let's see, we have the authentication authority that will create an
   authentication assertion. But then the attribute authority will generate the
   attribute assertion. And maybe, for doing that, she needs an authentication
   assertion. I first authenticate as professor of the Politecnico di Torino.
   And then I will get the permission to buy something. And then the policy
   decision point will create an authorization decision assertion. Great. But
   maybe, in order to take the decision, they need to know who is requesting
   and which attributes are possessed. So you see why I talk about
   producer-consumer. And finally, there is the policy enforcement point that
   will consume the authorization decision assertion. Each of these authorities
   have specific policies in order to decide how they should perform their
   tasks. And here, you see a generic system entity, an actor, a user, a
   process, or a device, that here made an application level request to the
   policy enforcement point. They said, no, no, no, wait a moment. I need a
   decision. And the PDP said, oh, in order to do that, I need identity and
   attributes. So attributes say, I need identity. I need identity. And so
   there is a credential collector, or if you prefer, an authentication
   protocol for going there. So all those things can work together in this,
   which is the most complex solution. Of course, for example, you could not
   have attributes if you have access control, which is identity-based. So it's
   enough to have the name of the person. Or vice versa, you could have an
   access control system in which identity is not important, but maybe location
   is important. Then the attribute authority could say, OK, I need to access
   your GPS to know your position, and then I will perform a statement. Yes,
   you are in this area, which is the only area permitted to perform this
   operation, and so on. So this is the more general schema. So multiple kinds
   of authorities may reside in a single system. We have separated them for a
   conceptual view. SAML permits, but does not require total federation of
   them. The arrows may not reflect information flow, because information may
   be pulled or may be pushed. Not all assertions are always produced. Not all
   potential consumers, clients, are shown. So that is a general and generic
   schema. Don't think of that as mandatory. OK. We said the SAML is specifying
   the data, so the assertion itself, and we have seen. But it's also
   specifying protocols. But not really the protocol for transferring, but the
   format of the data being transferred. And in general, SAML is defining the
   request for an assertion of a certain type, and the response containing the
   assertion. So there are two formats, one for an assertion request, and one
   for an assertion response. So there is the relying party, which is
   performing the request, and there is the asserting party. I made it in
   generic terms. Maybe the authentication server, maybe the attribute server,
   maybe the PDP. But it's someone providing the assertion that will provide
   the response. This part is not defined by SAML. SAML is defining those green
   objects. But the transport protocol can be anything. And typically, it's
   something at layer 7, because it's application oriented. Inside that
   application protocol, you use SAML for performing a request, receiving a
   response that will contain an assertion. So here in green, you have the
   three objects. SAML assertion request, SAML assertion response that contains
   a SAML assertion. So let's have a look at these formats. Request of
   authentication assertion. Conceptually, it is something like, please give me
   authentication information regarding this subject if you have any. So we
   assume that the requester and the responder have a kind of trust relation,
   because they must know that they are speaking about the same subject. And
   the response should be trusted. It is a sort of recommendation letter for
   the subject. This is an example. Now you see that the prefix is no more
   SAML. It's SAMLP, where the P stands for protocol. This is an element of the
   SAML protocol. It's the element of type request. Version, minor, request
   identifier, usual format, and then SAMLP. This is an authentication query, a
   request for authentication. The subject that I would like to have
   authenticated is in this domain, identified by this name. End of the query,
   end of the request. This is carried, for example, over HTTP in the web. And
   then he will receive a response. We said that we need a trust relation,
   because in general, the assertion is part of a triangle. Who accepts the
   assertion result must trust the entity that generated that assertion. In
   practice, we have two ways of establishing the trust relation, maybe push or
   maybe pull on a secure channel, for example, TLS. Or maybe via an XML
   signature with a shared or public key. We will see that, unfortunately, even
   if it is named XML signature, unfortunately, that is a bad name. Because an
   XML signature can be a real digital signature performed with public key and
   private key, or it can be a MAC computed with a shared symmetric key, which,
   of course, is giving you very different security features. I was discussing
   during the break with one of you. He was asking about the signatures. Is the
   signature really needed? If I have TLS, I don't need the signature. Correct,
   if that is just for yourself. But in case you want to cover your back in
   case of problems, you rather have a real signature. Let's imagine that I am
   the person in the front door of the Politecnico, and I have been instructed
   that today, no one must enter if they are not authorized by the rector. So
   the doors are closed. When you arrive, you show me a document. And I say,
   wait. I call over the telephone. You have a direct line with the rector.
   Hey, rector, there is this guy, Pippo Francesco, that wants to access
   Politecnico. Is it permitted or not? And the rector say, yes, let it in. OK,
   please come in. And you enter. You enter, and you destroy some rooms, some
   computers. And then the rector is coming after me. Why have you let enter? I
   say, oh, you told me. No, I never said that. Can you prove? That is the
   equivalent of TLS. I had a direct connection. You authorized me, but I
   cannot prove. So if anything goes bad, really bad. So let's change the
   procedure. There is Pippo Francesco here. Please, rector, come down, sign a
   piece of paper telling that I am authorized to let Pippo Francesco enter at
   this time. So if anything bad happens, hey, you authorized it. You signed
   it. That is the difference between having direct trust, like a TLS channel,
   or having a signature. And beware, if I want a signature, I want it with the
   public key, not with a shared key. Because again, if you have a shared key,
   you cannot distinguish the role. So that is also a caveat. We will discuss
   XML signatures. But if they call XML signature, and then it is done with a
   symmetric key, no use. For transporting some requests and responses over an
   application protocol, there are various bindings available. Because XML
   defines what to transport, while the bindings defines how to transport. So
   for example, the original binding was XAML with SOAP over HTTP. Is there
   anybody that knows what is SOAP? It was a thing maybe of 10 years ago,
   service-oriented architecture protocol. Nowadays, it's practically dead.
   XAML 2.0 has replaced that with XAML SOAP binding, or reverse SOAP. And as I
   said, these two are practically dead nowadays. Of course, these ones that
   are based on HTTP, which is the predominant protocol at application level
   nowadays, are very well in shape. We can have an HTTP redirect with GET, an
   HTTP POST, an HTTP artifact binding, or a XAML URI binding. And now, we
   analyze those systems to understand pros and cons of each solution. We
   discard the SOAP, as it's quite old, and we consider the others. In general,
   a XAML profile is a manifestation of a defined use with a combination of
   assertions, protocols, and bindings. In practice, a profile is a pattern.
   You know there are software patterns, network patterns, to make assertions
   relative to important information. So the web browser profile is to
   implement the single sign-on on the web. The SOAP profile is for assertions
   about the SOAP payload. And there are various of these profiles defined in
   the OSS standards. So this is the old one, just for history. Typically, we
   have XAML that contains a SOAP message with the SOAP header, SOAP body, and
   the request and response are carried inside this protocol. So it actually is
   layered in three protocols. This is the SOAP profile. This is a canonical
   way to express an assertion about a SOAP payload. So the assertion is
   related to what is contained afterwards. On the contrary, the things that,
   for us, are more relevant nowadays are the web browser profiles. There are
   three profiles that assume a standard commercial browser and HTTP, possibly
   much better S. But the user has authenticated to a local source site, and
   the assertion subject refers implicitly to the user. When a user tries to
   access a target site, a tiny authentication assertion reference travels with
   the request. So the real assertion can be the references. That is one
   possibility. Or the real assertion gets posted. You know the difference
   between GET and POST. With GET, you are limited in the quantity of data that
   you transfer. With POST, you can transfer whatever you like. So that's why,
   in the first case, we just send a reference, small. On the contrary, if we
   use POST, we can transfer the real assertion. And the choice of those two
   things is based on the agreement between the service provider and the
   identity provider. So let's start with the single sign-on PUSH use case.
   Client, identity provider, service provider. I go there, and I request
   service. I request a web page, HTTP, HTTPS. I don't care. The service
   providers, I know. I want authentication. So there will be a redirect. And I
   hope you know that in HTTP, there is a specific command for that. Do you
   know the number? 300. The class 300 of the responses is for redirect. And it
   contains the URL to which you are redirected. So there, there is a 300
   answer code that redirects you. But in the redirect, there is the
   authentication request. So the authentication request is contained in this
   redirect. Now, that is received and sent in the sense that now the
   authentication request gets sent to the identity provider. The identity
   provider will run a protocol of choice with you. That depends on the
   implementation of the authentication policy. Assuming that it is successful,
   then will create for you a form that, when you hit the Submit button, will
   send you to the service provider. And inside that form, there is a hidden
   field. And I hope that you know web forms, how they are organized. They can
   transfer all the data, including the hidden fields. And the hidden field
   contains the authentication response. Sorry. And now, the authentication
   response is submitted to the service provider. So typically, you run the
   authentication. And as a result of the authentication, you get a page with
   written authentication successful. Click here to continue. But that click
   here is hiding the fact that the click in there, you go back to the service
   provider, transferring the result. So you see, this model is-- which model
   with the reference of the first ones? No, there is no reference here. No, is
   when I push the ticket through the client. It's an indirect ticket
   transmission. There is no reference. Here, there is the real result. The
   ticket is the result. In this case, we don't call it ticket. We call it SAML
   authentication response. But you see that it is transferred, passing by the
   client. And let me say that, in this case, I would prefer to have it
   digitally signed, because otherwise, the client can change it. And finally,
   the service provider is providing the service to the user. So these are the
   steps. This is-- you get the service URI, redirect to the ADP with the SAML
   authentication request, and everything, as I have described, with the hidden
   field. This is also named a front channel exchange. Now, let's implement the
   other case, which is the single sign-on pool use case. Same actors, same
   initial step. Service request, redirect to ADP with authentication request
   embedded, authentication request, and authentication exchange. Nothing is
   changed up to this point. The change comes here. There is a redirect to the
   service provider. But this time, in the hidden field, does not contain the
   response, but contains what is named an artifact. In this world, artifact
   means a reference to the assertion. So now, the artifact is transferred to
   the service provider. And the service provider will need to open a channel
   to the ADP, submit the authentication response request. Please give me the
   response identified by this artifact. And now, it will receive the
   authentication response. This is more secure with respect to the client,
   less possibility of modification. But it requires the identity provider to
   accept incoming request from a service provider. And finally, the service
   will be provided, assuming positive authentication. So the steps are nearly
   the same. In blue, the modification. The artifact, which is a pointer to a
   SML authentication response on the identity provider. The POST will contain
   the artifact. And then, there will be a GET with the artifact. We just need
   a GET, because the artifact is a short reference. So no problem. And then,
   there will be the SML authentication response in the body of the response.
   This is named a back-channel exchange, because it's not passed through the
   front, the client, but hidden between the servers themselves. Let me make
   you another example. Because Google will use SML for performing
   single-sign-on when they are hosting applications for a company. So let's
   imagine that there is a company, Google Partner, that installs their
   application on the Google Cloud as a service provider. But the company wants
   to maintain control over authentication and authorization. So the
   application is running on Google, but the authentication is performed by the
   company. Of course, Google will have to ask to the company if a user is
   authorized or not. And that is the point where the company wants to maintain
   the control to avoid Google doing bad things. So the partner wants to
   maintain control over the authentication and the authorization, so they want
   to act as an identity provider. And the exchange is based on SML 2.0 with
   real public key signatures, because Google wants a proof that you have
   authorized this operation. So this is the schema. Here there is a user,
   typically an employee of the company, which tries to reach the application
   hosted on Google. Oh, I want to use the accountancy system of the
   Polytechnic Auditorium, but that is on Google. And Google say, OK, wait a
   moment. I've been told not to give access to anybody unless I am authorized.
   So Google will redirect the user to the single-sign-on URL. So it means that
   the partner, the company, must have a URL well-known to Google. Please send
   me the request here. Now the partner parses SML request. There is a SML
   request here. Please authenticate this user. We'll run an authentication
   protocol. Then we'll generate a SML response. And that SML response will be
   sent to the browser again. That SML response is sent to the ACS URL,
   Assertion Consumer Service, the service that will consume an assertion,
   which is the point where Google is waiting for the decision about the
   request. And if it is positive, user is logged in into the Google
   application and can perform operations. This is how it is used in a real
   environment, SML. So some details. The partner must provide to Google the
   URL of the single-sign-on service that can be also named the IDP, or the
   Authentication Server, as you prefer, and the X.509 certificate to verify
   the signature. Because the answer is signed with a real public key. Step
   three contains, in opaque mode, the URL of the Google service requested by
   the user. So the company knows not only, I have to authenticate, they can
   also perform authorization. Because this user is trying to use this service,
   the SML authentication request. And the URL where to send the response. And
   step six, in opaque mode, contains still the URL of the Google service to
   avoid a reply. If the company would say just user is authorized, that would
   not be good. I get that, and then I use it for another service. On the
   contrary, the answer must be tied to that specific server. The
   authentication response with XML SIG, and also the URL of the ACS. This is a
   response for this assertion consumer service. OK, great. So now we have seen
   SML for performing various kinds of operations. Not only authentication,
   also authorization and generic attributes. Now, let's go on to a bit more
   complex things. Federated identity, in general, augments federated
   authentication with identity-related attributes. In some cases,
   authentication is not enough. So, SML is often used to create federated
   identity system because it supports authentication and attributes. But we
   have a problem. And the problem is that we are using different devices. I
   see here in front of me a lot of laptops. But we use also this. Can we use
   the same kind of software on those and this? And the problem is quite
   tricky, because SML is providing a complete solution, but it's a bit heavy.
   Based on XML, XML is very verbose. Takes a lot of time to be processed and
   so on. So, heavy and difficult to support in lightweight or mobile
   environments. So, there is a competition. A new protocol and new data format
   has been invented, which is named OpenID Connect. So, SML is typically used
   for personal computer and server web-based environments. OpenID Connect
   makes similar things as SML, with the same architecture, client, service
   provider, identity provider, but focus on native web applications, because
   it does not use XML, but it uses JSON. And REST protocols. JSON and REST are
   native for Android and in general for smartphone. So, you don't need to put
   an extra software layer. If you use SML, you need to implement XML on your
   smartphone, which is not available. It's heavy and so on. Beware that OpenID
   Connect, in short OEDC, is not related to OpenID 2.0. But it's a very
   strange protocol, because it's an identity layer on top of OAuth 2.0, which
   is the IETF framework for authorization. So, it's very strange from a
   technical point of view. It's rather complex and involved, because you are
   using authorization to declare authentication. Normally, it's vice versa.
   You first have authentication and then authorization. So, the first message
   from this slide, SML good for servers, laptops, PCs, powerful systems. OEDC,
   better suited for mobile environments, smartphones, and so on. OEDC, less
   clear, less pure in its stratification, but it works. And so now, we have
   these two different solutions. So, let's have a look to this OpenID Connect.
   It's a delegated authentication system that uses JSON data and HTTP REST,
   which are native on any mobile operating system. Not correlated with the
   original protocol, because in original, inside the IETF, we had OAuth for
   authorization and OpenID for authentication. No, now OpenID is dead. OpenID
   Connect is not the evolution OpenID. It's an identity layer over OAuth 2.0.
   Great. The user agent can be a browser or can be a mobile app. And so, you
   just see the first orientation. The client that originally was the user, now
   is not the user. The client is the relying party wishing to use OpenID
   Connect for authentication. So now, we have one more element. You have the
   user agent, the one where the user is working, which is assessing a relying
   party. And the relying party is a client for OpenID Connect. OP, that I will
   use a shorthand for OpenID provider, is similar to the identity provider.
   But the difference is that it does not have one single endpoint for
   assessing its services, but has three different endpoints. The authorization
   endpoint that manages an authentication protocol, the token endpoint, which
   can verify if a token is valid or not, and the user info endpoint that
   provides additional user information if the user gives consent. Now, let's
   try to follow me on this schema. We have the user working with his user
   agent, a mobile app, a browser. I don't care. We have the client, which is
   the relying party. So you are going to a web page, for example, or you use
   your app to access a service. And you say, OK, I would like to log in with
   my Facebook credentials. Oh, OK. So this client say, I will generate an
   authentication request for Facebook and will redirect to Facebook. So the
   redirect will be get to the authentication authorization. Well, you see the
   confusion. Authorization endpoint, even if we are trying to do
   authentication. So we get this. We validate the authentication request. What
   is involved in this validate? This is Facebook. This is my service. How can
   I validate? The validation consists in the fact that I must check if this
   service is a friend of Facebook. We must have an agreement. And this request
   should be signed to demonstrate that it is coming from one client, one
   service, which is a friend of Facebook. OK, if the request is validated, an
   authentication page is generated. And the user will need to insert the
   credentials. Now, user's credentials enter. Post again to /authenticate with
   the credentials. Credentials are verified on the authorization endpoint. And
   now another page is displayed, authorization page. Maybe you have noted it
   happens when you use Facebook or Google for other authentication. But first
   you authenticate. And then there is a list. If you proceed, this data will
   be transferred. That is the authorization page, in which you have to express
   your consent. If you give your consent, you post to /authorize, going to the
   authorization endpoint. So you see why this is named authorization. But it
   is incorporating the authentication part. But in the end, it will be giving
   consent to generate the authentication response containing the information
   about the client. Now, this part was what was displayed before. And now we
   concentrate on the last part. Once you receive this, you go to the
   authorization of the client. So we will perform a GET to the callback of the
   authorization client. That was long ago. All my interactions have been with
   Facebook. But I'm going back to the client, so the service provider, which
   needs to verify if the token is correct or not. So I post /tokens with the
   authorization of the client. So here I'm going to the token endpoint, the
   one that validates if the token is correct or not. It will verify the
   authorization for the client. And then if the service provider requested the
   information, I want to know your name, surname, and your email address, for
   example, and maybe also your Facebook page. Now you do another callback. So
   this was already done. Now we have identity and account, which are verified.
   And optionally, you can use the GET user info with this account to retrieve
   the information. So as you think and see, it's much more complex and
   involves quite a lot of things. And the authentication is hidden. So in some
   sense, OpenID Connect contains everything in one specific protocol, rather
   than having the separate entities-- authentication issue, authorization
   issue, attribute issue. OK? I don't like it very much, but it works. And you
   will find it in several, several places. So trust, security, and discovery.
   Messages are authenticated with digital signatures. It means that
   registration of the public keys is required among the various actors. So
   when you become a friend of Facebook, you must submit the public key by
   which you will send your request. And vice versa, Facebook will tell you the
   public keys used by the various endpoints. Maybe they are different keys.
   All the messages exchanged are protected anyway via a secure channel, DLS.
   This is not a real federation, because SAML can really be used to federate
   different identity providers. This is not a federation. This is delegated
   authentication. You see the difference? It's delegated authentication,
   because that client, the relying part, the service provider, will need to
   have a trust relation with Facebook. If they want to use also Google, they
   need to create another association with Google, sending again the keys. So
   this is not federated. This is delegated authentication. We could use a
   service named WebFinger to discover OpenID providers if they are registered.
   But it's just discovery. There is no direct agreement. Anyway, well-known
   OpenID Connect providers are Google, Facebook, Salesforce, and others. But
   you need, if you want to be able to use any authentication for any users
   registered on this service, you need three different agreements. So no real
   federation, just delegated authentication. And you must enter into an
   agreement with that specific provider. Rather than assertions, OpenID
   Connect is talking about claims. And there are various profile categories.
   The subject, which is the identifier of the issuer. Name, given name, family
   name, blah, blah, blah, blah. You see, quite a lot of things. The email
   category is the email, and if the email has been self-declared or verified.
   Because remember that one important thing, when you register with Google,
   you are not providing any proof. You can declare whatever name you like. The
   only thing that will be actually verified is the email address and maybe
   your phone number, if you decide to verify that. All the rest is
   self-declared. Phone category, phone number, and if the phone number has
   been verified or not. And address category, the address, which, of course,
   cannot be verified in the electronic world. So a client, that is a service
   provider relying on one of those providers, may request specific claims or a
   whole category. The category is named the scope. For example, I can claim
   family name, so just one value. Or I can ask scope, OpenID, email, and
   phone. So the identifier, your email address, and your phone number. Scope,
   OpenID, is compulsory in all requests to declare that OAuth 2.0 is used for
   OpenID Connect. Apart from the ones with verified equal true, all the others
   are self-asserted by the user and, hence, completely unreliable. We will
   compare that with another usage of SAML that we will see in a moment, in
   which, on the contrary, the emphasis is on the fact that SAML is providing
   validated data and not self-declared data. Custom claims may be used, but
   they have, of course, a restricted audience. You must agree about these new
   claims. Claims are transferred in the form of a Java Web Token, JWT. So this
   is an example of an ID token, in which we want subject, issuer, audience,
   that is the client for which this is generated, nonce, ACR, Authentication
   Context Cluster Reference. EAT stands for Issued At and Expiration. So you
   see, this is a standard JSON. Subject, Alice. Issuer, this supposed OpenID
   Connect service. Audience, didactic apolito IT, not with the dots, but
   because of a name. Nonce, to avoid the replay attacks. Authentication time,
   this. ACR, this is the Context Cluster Reference. High security, it means it
   has been validated very strongly. Maybe one-time password, maybe challenger
   is symmetric. And then issuer, this time, and valid for 10 minutes. That is
   the expiration. OK, I think we can stop here for the second break, and then
   we will talk about how these things are implemented for real federated
   authentication. Here it is. So, ADAS. What is this strange name? It's quite
   important nowadays. ADAS is a regulation of the European Union. Back to
   2014, so 10 years ago, is electronic identification, authentication, and
   trust services. In this presentation, we will focus on the first two terms,
   identification and authentication, to provide security for electronic
   transactions in the internal market. So, internally to the European Union.
   As you can see, ensures that people and businesses can use their own
   national electronic identification schemes, because Europe is not a single
   country. Europe is many countries with something in common, and each country
   has decided a specific way to give electronic identity to the citizen. So,
   one component of ADAS is to create interoperability between the different
   systems. In that sense, it is creating a federated authentication system.
   This national electronic identification scheme, ADAS, will be used to access
   public services in other European countries where also ADAS are available.
   Was adopted in this data. The ADAS infrastructure was initially voluntary,
   but since 2018, it is compulsory. All members of the European Union must
   have this system in place, and must permit access to the citizen of other
   countries to use that. That is compulsory for public services. There is now
   ongoing discussion for private sector. The private sector, insofar, is
   optional. They can use that, but they are not forced to use that, because
   regulations apply only to public services. So, purpose and principles. To
   boost confidence and trust towards the digital world by adopting some
   principles. First of all, mutual acceptance of national AD. If you are
   Italian, you can use your speed or electronic identity card, whatever in
   Europe, and vice versa for the other citizen. So, to create a common
   framework for secure interaction between citizens, companies, public
   administration. One problem, each country has taken a different decision.
   There are some countries with passwords, some countries with smart cards,
   some countries with smartphones. A nightmare. So, we had to create something
   that was technologically neutral, so should not be required or restricted to
   a specific solution for authentication. Whatever is valid for you in your
   country, we will accept. But, we are not stupid. If in your country you are
   using username and password, you cannot be trusted as much as another one
   using smart cards with the ECDSA 1,000 bits. There are differences. So,
   there will be a level of trust in what you do in national electronic
   identity, defined by a certain EAD quality level. And then, there is a group
   of people that supervision the application and take the decision about these
   trust levels. There are several implementing acts. The procedural
   arrangement for cooperation between the MS, means member states, the
   interoperability framework, the technical specification for the assurance
   level, and the format and procedures for notification. Notification means
   notify to the other countries that there is a specific solution for
   electronic identity in my country. So, the concept of a pan-European
   electronic identifier was not simple. I've been the Italian delegate for
   this thing for more than eight years, and I've learned quite a lot of things
   in creating this system. First of all, the electronic identity is not just
   authentication. It's authentication plus attributes. And I would like to
   stress the word "certified attributes." Because compared to a generic XML or
   to a generic OpenID Connect, the difference here is data are provided by the
   government. So, they are the official data. They are certified attributes.
   When I say that this person performing this transaction has a surname Lioi,
   that is a real statement. When the government say, yes, that is true, we
   have verified. So, that's a big difference with other systems. So, we
   defined a set of certified European attributes. We have discussed among the
   various countries if those kind of things can be distributed by all
   countries. And we had to take several decisions, some of them complex but
   relatively simple, like the lexicon. We must define the attribute names in
   all possible languages of the European Union. Then, the syntax. OK, there is
   this thing, but how do you write that? Very simple example, address. In
   Italy, we write the address in a simple form. For example, via Roma 22. But
   if you write that in the British country, the address is 22, Roma Street.
   So, where is the number? In the end, in the beginning. So, we need to define
   the syntax for each specific attribute. And then, the semantics. What is the
   meaning of that attribute? For example, surname, family name. For us in
   Italy, no problem. I have discovered that if you live in Iceland, you will
   have two surnames. Because when you are born, you are assigned automatically
   the surname of your father and your mother. And you can use any of them or
   both of them simultaneously. So, asking to an Icelandic citizen, what is
   your surname? We say, which one? And that's a problem that needs to be
   solved. Otherwise, we don't have interoperability. Then, these various
   authentication credentials. We have made the survey. And there are some
   countries that use reusable passwords. Whoa. Other one-time password,
   smartphones, software certificates, smart cards. So, there are all possible
   solutions around Europe. The point is that we must permit all those means to
   be used in a transparent way and with legal value. Where, beware, the legal
   value is according to the legislation of the emitting country. If your
   country accepts username and password, great. And you are responsible for
   what happens with just an insecure system. So, we try to have a bit of
   adaptive security and a bit of privacy protection. First of all, since the
   different countries use different mechanisms for authentication, we don't
   give them the same grade. But we have different grades. The grades are
   basically three. They are named level of assurance, low, substantial, and
   high. And they are based not only on the cryptographic strength of the
   authentication technique. So, for example, username and password is low.
   Smart card-based asymmetric challenge response is the highest. Great. But we
   keep into consideration also the way in which the citizen is identified when
   given an electronic identity. Because there are some countries in which the
   citizen is permitted to send a letter, please give me my smart card, and the
   government will send the smart card. Oh, have you really identified the
   citizen? So maybe the technical solution is very strong. The identification
   procedure is not so good. So the level of assurance is keeping into account
   these two different things. It's not enough to have a strong technical
   solution. You need also to have a strong identity verification to associate
   the credential with the citizen. Then we will have the client, the claimant,
   and the relying party. And we may have a mismatch. Because for accessing a
   certain service provider, that service provider is requiring a lower
   minimum. I need at least a substantial. You are using username and password,
   but that is low. Sorry, low is below substantial, not permitted. So there
   can be a mismatch. Yes, you are identified, but you are not strong enough to
   access this service. For privacy protection and localization, where
   localization means not to know where you are, but means talking with your
   local language and your local habits. So in general, you will see that in
   the system, the user talks with their own country and provides explicit
   consent for the required attributes. Because there is another part, which is
   privacy protection. When we export citizen data to another country, we must
   be permitted to do that. Because normally, your personal data can be used by
   your national government. You must give permission to export that to a
   different government. Second, in order to protect the data, attributes that
   are the data of the citizen are managed end to end. That is, the
   infrastructure in between is not reading and is not storing the data. And
   finally, there are options for attributes that protect the data with minimal
   disclosure, following the principle of the need to know. For example, one
   thing which is often requested is, I don't need to know your exact birth
   date. If I just need to verify that you are above 18. So one possible query
   is, please tell me if the user is above or below this age. In that way, I
   protect your privacy. You don't disclose your birth date. A bit of
   terminology. MS stands for member state. And we talk about a sending member
   state, which is the member state whose ID schema is used in the
   authentication process. And we'll send, as a result, an authenticated ID.
   Receiving member state is the member state where there is the relying party,
   which is requesting an authentication. ADAS connector. That is a node
   requesting a cross-border authentication. So each country has an ADAS
   connector, which is the one connecting all the relying parties in that
   country with the rest of the infrastructure. ADAS service, on the contrary,
   is a node which provides the service of cross-border authentication.
   Unfortunately, that can be implemented in two ways. Most of the countries in
   Europe use an ADAS proxy. So it's a service operated by the sending member
   states in which you can request, I will perform authentication and send the
   result. All countries but Germany and Austria. Germany and Austria are using
   a different solution, which is named ADAS middleware service, in which the
   service is not run by Germany or Austria, but is managed by the country
   where the service provider is installed. Let's make an example. I'm an
   Italian citizen. I'm just moving to Sweden. And I wanted to enroll my kids
   in a public school in Sweden. So I connect to a service provider, the school
   in Sweden, which will ask me to identify and say, wait a moment. I want to
   use my Italian connection. So I want to use ADAS. So the school will
   redirect me to the Swedish ADAS connector. So the exit point from Sweden to
   the rest of Europe. Great. When I arrive to that node, I will need to
   specify that I'm from Italy. So I select my country. And they will be
   redirected to the Italian ADAS service, which in this case is a proxy
   because we have implemented a proxy. Now, the Italian service will talk,
   first of all, Italian. And the rest is in English or maybe in Swedish. And
   we'll not only talk my language, but we'll also provide some warnings. The
   first warning is beware because for enrolling your kids in that school, that
   school has requested your name, surname, date of birth, date of marriage,
   and name of your wife, blah, blah, blah, blah, blah. Do you intend to
   transfer this data to Sweden? Because if you have no intention, please stop
   here. Don't go on. If you decide that you will give consent, please just
   tell me which is your Italian identity. Because we can have a speed, or we
   can have electronic identity card. And if you have speed, you may have
   postal. You may have this. You may have that. So it's a nightmare in Italy.
   But it works. So I will tell which electronic identity I want to use. And
   they will be redirected to that node, which is implementing identity
   provider and attribute provider, of course, Italian. Now, I will run an
   authentication protocol. You may have seen that a smart card has appeared.
   That is a possibility. There are other ways for performing authentication.
   Now, the authentication is successful. The government knows which are my
   data. And now, there is the final consent. Let me summarize. They requested
   your name, Antonio. They requested your surname, Leo. They requested this,
   this. So now, I have the list of all the data with the values that will be
   transferred. This is your last option. If you click OK, data will be
   transferred to Sweden. If I click OK, we will go back with a series of
   redirects following the same path until my data are transferred to Sweden.
   The intermediate node, the ADAS connector and the ADAS server are not
   storing the data. Actually, the data are encrypted in that part and will be
   decrypted only at destination in order to protect our privacy and avoid any
   problem with intermediate nodes. I would like to stress the fact that the
   ADAS part is these two machines. The ADAS regulation is saying how these two
   machines are talking-- well, two. All those machines are talking among them.
   Because this part here is a matter of national regulation. This part here is
   another matter of technical regulation of that country. So the ADAS
   infrastructure is governing the connection between the ADAS connectors and
   the ADAS services. Local connections can be done in another way. And this
   part here is done with SAML, because they are big servers. Then each
   country, locally, may decide to use SAML or may decide to use OpenAD
   Connect. I don't care, because that part is used here in the dialogue
   between the citizen and the local authority. The result will be SAML,
   because the ADAS service is accepting only SAML. And here is the same. This
   will be in SAML format. That's important, because it means that, locally,
   you don't need to change all the servers or the identity providers that you
   have in Italy or in another country. You just need to add to your solution
   these nodes and to make them talk with the local nodes for accepting
   requests, like in this case, or providing answers, like in step 4. So there
   are various technical specifications to be followed. Currently, we are at
   version 1.2. They are all publicly available, of course. You can review them
   at this URL. They were based on the Stork 1.0 project. That was the first
   step towards this architecture. It's similar, but not perfectly compatible,
   because initially, we did not perform encryption of the authentication
   response. Then, after complaints by some member states, we decided, OK, we
   add encryption. And covers, only for the international part-- so member
   state to member states-- the architecture, the format of the messages, which
   attributes are supported, and the cryptographic requirements. Locally, you
   can do whatever you want. But for the international span of this
   architecture, those are defined by that regulation. So ADAS is defining a
   minimum data set, which needs to be supported by any ADAS nodes. There are
   eight attributes for a natural person. And it's mandatory-- a person
   identifier, first name, family name, and date of birth. Optional-- birth
   name, place of birth, current address, and gender. There are also 10
   attributes for legal persons. That is an interesting fact. We are not only
   identifying humans, but we are also identifying roles. For example, you can
   authenticate to ADAS saying, I am the rector of the Politecnico. I am the
   president of Reply. And in that case, when you authenticate in that way, the
   mandatory part is the legal name of the company and the legal personal
   identifier, where this means president, CEO, rector, and so on. And then
   optional-- legal address, the VAT, in Italian, IVA, tax reference, business
   codes, and the series of identifiers that are used for companies in an
   international way. Security requirements-- some requests, which does not
   contain any personal data, because it's just containing the list of
   attributes, the minimum data set, must be signed. Requests may be
   transmitted via HTTP array direct with a 302 GET with a request in a
   parameter. And this is the preferred solution if the request does not exceed
   the maximum URI length. And you know that parameters can be at most 255
   bytes. Or an HTTP POST with a request in a hidden field, which is valid for
   whatever is the general case. That typically depends on how big is the list
   of attributes that you are requesting. The response that contains personal
   data must be signed. And you say, only signed? Yes, it's signed. But it
   contains an encrypted assertion with one authentication statement and one
   attribute statement. So the answer is assigned. So it is demonstrating that
   that answer is coming from that country. Internally, it contains the
   authentication result and the attributes required. And those are encrypted
   for the destination. And that is transmitted via POST, because typically
   it's a big one, with binding to the ACS of the ADAS connector. Of course, we
   need to know the public keys, the encryption keys of all these nodes around
   Europe. So there is a public registry for connector metadata that contains,
   among others, the encryption certificate and the ACS URI. Those are public
   data available to everybody. Connections are performed via TLS. That's
   compulsory. Minimum version 1.2. We expect in a short time to migrate to
   1.3. But for the moment, 1.2 is the minimum to be accepted in this
   federation. The bad point is that they are requiring the qualified web
   certificates. We have not yet discussed what is a qualified web certificate.
   I will do in one of the next lectures. But it's something which is not very
   well used and known. Actually, they request the qualified web certificates,
   but the actual infrastructure accepts also normal certificates. As a cipher
   suites, you see that for signature and key exchange, we have elliptic curve
   with Diffie-Hellman and DSA, or elliptic curve plus RSA, or also normal
   Diffie-Hellman and DSA. Encryption, AS128 or 256 with CBC or GCM with
   SHA-256 and 384. SHA-1 may be accepted due to restrictions on the client. So
   if we are using TLS, there is the problem that maybe some browsers do not
   support yet those things. So when you use elliptic curve, minimum 256-bit.
   If you use normal integral cryptography, minimum 2048. TLS compression must
   be disabled. We have discussed that there are a lot of attacks possible. TLS
   heartbeat and session renegotiation must not be supported, again, to avoid
   some attacks. If CBC-based cipher is used, first encrypt and then
   authenticate. So it's compulsory to configure TLS with encrypt then MAC. And
   don't use a truncated HMAC. That is an extension with respect to TLS, and
   that should not be supported. For the crypto requirements for the SAML part,
   data encryption is with AS-GCM 128 or 256. It's optional to use 192. Key
   encryption with optimal RSA padding, but in that case, 3k minimum key
   length. Key agreement via elliptic curve ES. Elliptic curve Diffie-Hellman
   ES. Ephemeral static mode. It means the recipient, the destination, has a
   static Diffie-Hellman parameters, while the sender creates an ephemeral
   ones. So it's a middle point between having static or completely ephemeral.
   Will you tell me, just to have some interaction, why this choice and not,
   for example, completely ephemeral? , Sorry? [AUDIO OUT] I not completely
   followed you, but the privacy is protected by the fact that data are
   encrypted. Now with the elliptic curve Diffie-Hellman, we are agreeing about
   the key. So why in this agreement, I create ephemeral, but I use the static
   keys of the destination? Because given that schema, the destination is the
   one to which you are sending the encryption. And you are not talking to the
   destination. You remember, who is the destination? It's the server in
   Sweden, which is not directly talking to you. But they can publish, this is
   my key. And so for you, it's simple to create an ephemeral key, because
   that's my key. And then I will use the static key of the destination. So
   since destination is well known, that will be published in a set. But in
   order to improve security, at least one part is ephemeral. Keywrapping via
   AS_KEYWRAP, digital signature, if you use RSA, minimum 3072. If you use a
   CDSA, minimum 256, with any of the SHA-2 family. For the elliptic curve,
   there is a list of specific curves that may be used and agreed. If you want
   to try by yourself, here is the list of some services available also to
   Italian citizens, but to any citizen. For example, for L1, that is LOW, you
   can use EUROPASS. When you create your European passport, or your CV, you
   can use your European identity, your speed, or your Italian identity card.
   These services need at least level 2, so LOW substantial. This is the
   Belgium tax declaration system, and this is the Sweden tax declaration
   system. If you want to test the service requiring LOW high, this is this
   service from Austrian government. I don't understand what it's doing. It's
   completely in German. But if I don't have layer 3, I cannot perform LOW. If
   I don't have layer 3, I cannot perform LOGIN. Just to show you some
   examples, but you can try by yourself. I assume that you have speed or
   something like that. That is the currently running system. Now, there is an
   increasing effort to go towards other things. In particular, going to
   self-sovereign identity. I don't know if you have had some course talking
   about that. No. Self-sovereign identity is a new trend in which we don't
   want the government to distribute the information. We want the government to
   generate the information, but you to be able to manage that information by
   yourself. For me, it's a very dangerous concept because even if you create
   good security procedures, it relies on the normal user to do the right
   things. And I don't trust the normal users for taking good decisions. But
   anyway, that is the trend and we will follow. So the new schema is based on
   a thing named UADI, UIDigital Identity Wallet. Do you have the I/O app,
   Italian? You may have seen that now we have been able to add our health card
   and your driving license. That is an example. For the moment, those things
   are limited to Italy. They are not valid for the rest because the I/O app
   was devised before the European digital wallet. They say, but knowing the
   Italian government, I don't trust that so much. But in 2025, that will be
   migrated to something which is compatible with the UDI. And in that case,
   you will be able to use those electronic things also in other countries. So
   anyway, it implements the concept of self-sovereign identity, providing
   identification and authentication, verifiability of the validity of the
   evidence by third parties across Europe, secure storage and presentation of
   verified identities, and generation of qualified electronic signature. So it
   seems a bit more wide than not just authentication and attributes providing
   of the current IHS 1.0. OK, let me finish this talk with the Italian
   solution, SPID. This is the Italian Public Services for Digital Identity
   that, with respect to the other solutions, has one more element. Because in
   Italy, we have the identity provider, which performs user enrollment and
   authentication and the returns identity plus some basic attributes, not all
   the attributes. Then we have service providers that, based on the identity
   and attributes, perform access control. And in theory, we have also
   attribute authority, because there are some attributes that are not
   controlled by the government. For example, I hope you will become an
   engineer, and maybe you will enroll in the professional engineers, Ordine
   degli Ingegneri. But that is not controlled by the government. So if you
   want to make a statement, I am a professional engineer, then you need an
   attribute authority creating that statement. So that is the purpose of an
   attribute authority, to create some additional statements that, in theory,
   is present in the architecture of SPID, but not implemented currently. SPID
   is using SAML version 2 with the web browser SSO profile. So you go back to
   what I've described today. But here, each entity provides its own metadata
   that contains the IS509 signature certificate, which may be self-signed.
   Because anyway, this list is published on a government controlled site. So
   even if it's not issued by certification authority, no problem. The protocol
   endpoints, other data such as the supported attributes. For example, Aruba
   is one of the SPID providers. And if you go to that page, you can read the
   metadata associated with that service provider. The metadata are signed by
   the Agency for Italian Digitalization in detached form. What that means will
   be the target of electronic signatures that we will discuss probably
   tomorrow or next week. The official metadata registry containing all the
   service providers and identity providers is at this address. And we are a
   bit back in specification because we use RSA 2048, while at the European
   level, we require as minimum 3,072. In case of an HTTP redirect, the SAML
   request is passed in the query string of a GET. But this has limited
   dimension, OK? So minimum is 256. Lengths up to 2 kilobytes are accepted.
   Maximum 8 kilobytes. So we decided, since we don't want to use the POST,
   that the SAML request is compressed with the FLATE and not signed with
   XMLDSIG. But with the SIG_ALGUMENT parameter specified. And the signature
   parameter contains the base 64 URL-encoded signature of the whole query
   string. So we are doing some specific things of Italy, even if, in general,
   we are using SAML. When using HTTP POST, then we permit normal SAML with
   normal XML signature. That is the bad point of such a specification. To
   force people to implement two different ways of doing the same thing. No,
   please, just do one. Avoid. Now, this is unnecessary complexity, for
   example. For the data, there are many basic attributes. And each service
   provider may require not single attributes. Attributes are grouped in
   attribute set. For example, one basic attribute set is name, family name,
   fiscal number, and email. That is compulsory. Any IDP must provide that. And
   here, also, we have authentication level. Speed level 1 is static password.
   Speed level 2 requires, as a minimum, two-factor authentication. Maybe
   static password if you want a password. Password plus the use of an app.
   While speed layer 3 is two-factor authentication with asymmetric
   authentication via a secure device. So maybe password and an app for remote
   digital signature and a layer 3 PIN. Evolution. As I said, the attribute
   authority is not yet active. Basically, not for technical, but for
   organizational problem. The government has not decided who is authorized to
   create some attributes. And there is also a push for making speed available,
   not only with SAML, but also with OpenID Connect. This is compulsory for the
   IDPs since May 1, 2022. For the service provider, it is optional to support
   that. And that's all for tonight. See you tomorrow. [NO SPEECH]
   [BLANK_AUDIO]
